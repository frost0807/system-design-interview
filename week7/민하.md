# 13장 검색어 자동완성 시스템
입력 중인 글자에 맞는 검색어가 나오는 것을 보통 검색어 자동완성
(autocomplete, typeahead, search-as-you-type, incremental search) 라고 한다.
<br>

## 문제 이해 및 설계 범위 확정
### 요구사항
- 빠른 응답 속도: 페이스북을 예로 들때, 시스템 응답 속도는 100밀리초 이내
- 연관성: 자동완성어가 입력 단어와 연관되어야 한다.
- 정렬: 정렬 결과는 인기도 순위 모델에 의해 정렬
- 규모 확장성: 트래픽 감당할 수 있도록 확장
- 고가용성: 예상치 못한 네트워크 문제에서도 계속 사용 가능해야 함

<br>

### 개략적 규모 추정
- DAU 천만 명
- 사용자당 10건 검색
- 20바이트 데이터 입력
- - 문자 인코딩은 ASCII 사용, 1문자 = 1바이트
- - 질의문은 평균 4단어로 가정, 각 단어는 평균 다섯 글자
- - ∴ 20바이트
- 글자 입력 할때마다 검색어 자동완성 백엔드 요청
- 초당 24,000건 QPS => (10,000,000×10(query)/일×20자/24시간/3600초) = 약 **48,000**
- 질의 중 2%는 신규 검색어일 때, 0.4GB의 신규 데이터가 시스템에 추가

<br>

## 개략적 설계안 제시 및 동의 구하기
### 데이터 수집 서비스
사용자가 입력한 질의를 실시간 수집하는 시스템<br>
query 와 사용빈도를 저장하는 빈도 테이블이 있다 가정할 때, 처음엔 빈 테이블로 존재한다.
<br>사용자가 'twitch', 'twitter', 'twit-ter', 'twillo'를 순서대로 검색할 때,
빈도 칼럼에 횟수를 추가하며 변한다.<br>

### 질의 서비스
빈도 테이블이 아래와 같을 때, query 와 frequency 가 있다.

| query        |  frequency  |
|--------------|-----------|
| twitter           | 35    |
| twitch   | 29    |
| twilight     | 25    |
| twin peak        | 21      |
| twitch prime      | 18 |
| twitter search      | 14 |
|  twillo      | 10 |
| twin peak sf      | 8 |

사용자가 "tw"를 입력하면 top 5 자동 완성 검색어가 표시되야 한다.
데이터가 작을 땐 괜찮지만, 많아지면 병목 현상이 일어난다.
<br>

## 상세 설계
### trie 자료구조
개략적 설계안에서는 RDBMS 를 사용했지만 TOP 5 를 골라내는 방안은 효율적이지 않다.
<br>트라이가 시스템의 핵심적 부분이 되므로 기본 트라이를 이용하여 최적화하고 응답 시간을 줄인다.
<br>트라이 자료구조의 핵심 아이디어는 다음과 같다.
- 트라이는 트리 형태의 자료구조
- 트리의 루트 노드는 빈 무자열
- 각 노드는 character 하나를 저장하며 26개의 자식 노드를 가질 수 있다.
- 각 트리 노드는 단어, 접두어 문자열(prefix string)을 나타낸다.

기본 트라이 구조는 노드에 문자를 저장한다. 아래 빈도 테이블을 가정해 보자.

| query        | frequency |
|--------------|-----------|
| tree         | 10        |
| try          | 29        |
| true         | 35        |
| toy          | 14        |
| wish         | 25        |
| win          | 50        |

빈도 테이블을 이용하여 트라이 노드에 저장하게 된다. 
- p: prefix(접두어) 길이
- n: 트라이 안의 노드 갯수
- c: 주어진 노드의 자식 노드 갯수
<br><br>라고 할 떄, 가장 많이 사용된 query K개는 다음처럼 동작한다.
<br><br>
- 접두어를 표현하는 노드를 찾는다. 시간 복잡도는 O(p)
- 해당 노드부터 시작하는 하위 트리를 탐색, 모든 유효 노드를 찾는다. 시간 복잡도는 O(c)
- 유효 노드를 정렬하여 가장 빈도 높은 검색어 K개를 찾는다. 시간 복잡도는 O(clogc)
<br><br><br>

K=2, 검색창에 'be' 를 입력했을 때, 프로세스는 다음과 같다.
1. 접두어 'be' 찾기
2. 해당 노드부터 시작하는 하위 트리 탐색하여 모든 유효 노드 찾기
   (그림 13-7의 경우 [beer: 10], [best: 35], [bet: 29])
3. 유효 노드 중 2개를 정렬하면 best, bet 을 골라낸다.

<br>
시간 복잡도는 각 단계별로 **O(p)+O(c)+O(clogc)**이다.
<br>그러나 전체 트라이를 검색하는 최악의 경우도 있기 때문에<br><br>
(1) 접두어 최대 길이 제한<br>
(2) 각 노드에 인기 검색어 캐시<br>

로서 해결할 수 있다.<br>


#### 접두어 최대 길이 제한
사용자는 긴 검색어를 쓰는 일이 드물다. p 값은 작은 정수로 정하면 시간 복잡도는
O(1)이 된다.
<br><br>

#### 노드에 인기 검색어 캐시
노드 k에 인기 검색어를 저장하면 전체 검색하는 일을 방지한다. 자동완성의 경우 5개의 질의로
정한다. 각 노드에 인기 검색어 5개를 캐시하면 시간 복잡도를 낮출 수 있으나 저장 공간이 많이 필요하다.
<br><br>

따라서 두 최적화 기법을 적용하면 시간 복잡도는 다음과 같이 달라진다.
1. 접두어 노드 찾는 시간 복잡도는 O(1)
2. 최고 인기 검색어 5개를 찾는 질의 시간 복잡도는 O(1). 검색어가 미리 캐시되어 있기 때문
<br>인기 검색어 K 개를 찾는 시간 복잡도는 O(1)이 된다.

<br>

### 데이터 수집 서비스
타이핑시 실시간 데이터 수정의 경우 실용적이지 못하다.
1. 매일 입력하는 질의를 그때마다 갱신하면 질의 서비스는 느려진다.
2. 트라이가 만들어지면, 인기 검색어는 자주 바뀌지 않을 것이라 갱신 필요가 없다.

<br>

규모 확장 쉬운 데이터 수집 서비스를 만들기 위해서 데이터가 어디서 오는지, 어떻게 이용되는지 알아봐야 한다.
트위터의 경우 검색어를 최신으로 유지해야 하지만 구글은 그럴 필요가 없다.
<br>
![img](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FdFm4kS%2FbtsIGkoQpNQ%2Fhh8qjJoBH1H0ExPnrG9drK%2Fimg.png)

**데이터 분석 서비스 로그**
데이터 분석 서비스 로그에는 입력된 질의에 관한 원본 데이터가 보관된다.
새로운 데이터가 추가되고 수정은 안됨. 로그 데이터에도 인덱스 없음

| query | time                |
|-------|---------------------|
| tree  | 2024-07-20 22:36:01 |
| try   | 2024-07-20 22:36:05 |
| tree  | 2024-07-20 22:36:30 |
| toy   | 2024-07-20 22:37:01 |
| tree  | 2024-07-20 22:37:11 |
| try   | 2024-07-20 22:38:21 |

**로그 취합 서버**
<br>데이터 분석 서비스 로그는 양이 많고 데이터 형식이 다른 경우가 있다. 데이터를 취합하여 사용할 수 있도록 해야한다.
취합 방식은 용도에 따라 달라지지만 대부분 주마다 취합하는 것이 충분하다. 면접장에서는 실시간성이 중요할 것이다.
<br><br>

**취합된 데이터**

| query | time       | frequency |
|-------|------------|-----------|
| tree  | 2024-07-01 | 12000 |
| tree  | 2024-07-08 | 15000 |
| tree  | 2024-07-15 | 9000 |
| toy   | 2024-07-01 | 8500 |
| toy   | 2024-07-08 | 6256 |
| try   | 2024-07-15 | 8866 |

매주 취합한 데이터라고 가정했을 때 time 필드는 시작 날짜를 나타낸다.
frequency 필드는 주에 사용된 횟수 합이다.
<br><br>

**작업 서버**
<br>작업 서버(worker)는 비동기적 작업 실행하는 서버 집합이다. 트라이 자료구조 생성->트라이 DB 저장을 한다.
<br><br>

**트라이 캐시**
<br>분산 캐시 시스템으로 트라이 데이터를 메모리에 유지함으로 읽기 연산 성능을 높인다.
매주 트라이 DB 스냅샷을 남겨 갱신한다.
<br><br>

**트라이 데이터베이스**
<br>지속성 저장소다. 두가지 선택을 통해 사용할 수 있다.
1. 문서 저장소: 매주 새 트라이를 만들어 직렬화하여 데이터베이스에 저장한다. 몽고DB 를 활용하면 편하다.
2. 키-값 저장소: 
   - 트라이에 보관된 모든 접두어 해시 테이블 키로 변환
   - 트라이 노드에 보관된 데이터 해시 테이블 값으로 변환

<br><br>
**질의 서비스**
1. 검색 질의가 로드밸런서로 전송
2. 로드밸런서는 API 서버로 전송
3. 데이터가 트라이 캐시에 없을 경우, DB에서 가져와 캐시에 채운다.

<br>
질의 서비스는 빨라야 한다. 최적화 방법도 고려해 봐야 할 사항이다.

- AJAX 요청: 웹 어플리케이션의 경우 브라우저는 AJAX 요청을 보내 자동완성된 검색어 목록을 대개 가져온다.
새로고침 할 필요가 없는 장점이 있다.
- 브라우저 캐싱: 보통 애플리케이션의 경우 자동완성 검색어 제안 결과가 바로, 자주 바뀌지 않는다. 브라우저 캐시에 넣으면 바로 가져갈 수 있다.
- 데이터 샘플링: 대규모 시스템의 경우 질의 결과를 로깅하면 CPU 자원, 저장 공간이 소비된다. 샘플링은 N 개 요청 중 1개 로깅하도록 하여 효율성을 높인다.
  
<br>

**트라이 연산**
<br>작업 서버가 담당한다. 데이터 분석 서비스 로그나 DB 로 취합된 데이터 사용한다.
<br><br>

**트라이 갱신**
두 가지 방법이 있다.
1. 매주 한번 갱신: 새 트라이를 만들고 기존 트라이 대체
2. 트라이 노드를 개별로 갱신: 성능이 좋지 않다. 트라이가 작을 떈 고려할 만 하다. 노드 갱신시 상위 노드도 갱신해야한다.

<br>

**검색어 삭제**
<br>위험한 질의어는 자동완성 결과에서 제거한다. 필터 계층을 두고 부적절한 질의어를 걸러낸다.
물리적 삭제는 업데이트 사이클에 비동기적으로 진행한다.
<br><br>

**저장소 규모 확장**
<br>첫 글자 기준 샤딩하는 방법을 생각할 수 있다.
- 검색어 보관으로 두 대 서버가 필요하면 'a'~'m'은 첫 번째 서버, 나머지는 두 번째 서버에 저장한다.
- 세 대 서버가 필요하다면 알파벳을 세 구간으로 나누어 저장한다.
<br>
이런 경우 최대 26대로 제한한다. 그러나 단어의 분포가 다르기 때문에 알파벳 길이로 데이터를 저장하는 것은 효율적이지 않다.
단어 양에 따라 분배하는 것이 적절하다.

<br>

## 마무리
생각 해볼 거리
- 다국어 사용할 경우: 유니코드 데이터 저장
- 국가별 인기 검색어 순위가 다를 경우: 트라이를 CND 에 저장하여 응답속도 높임
- 실시간으로 변화하는 검색어 추이를 반영하려면: 
  - - 샤딩을 통해 작업 대상 데이터 줄인다.
  - - 순위 모델을 바꿔 최근 검색어에 높은 가중치를 둔다.
  - - 데이터가 스트림 형태로 올 수 있다는 점을 고려한다.
<br>
<br>
  
***
# 14장 유튜브 설계
유튜브엔 다양한 기술이 내재돼 있다. 2020년 기준 유튜브의 서비스는 다음과 같다.
- 월간 능동 사용자: 20억
- 매일 재생된 비디오: 5십 억
- 미국인 사용자 : 73%
- 5천만 명의 창작자
- 2019 년 기준 150억 달러 광고 수익료
- 모바일 인터넷 트래픽 37% 차지
- 80개 언어
  <br>

## 문제 이해 및  설계 범위 확정
- 비디오 업로드, 시청
- 모바일 앱, 웹, 스마트 TV
- DAU 5백만 명
- 사용 시간: 30분
- 다국어 지원
- 비디오 해상도 지원
- 암호화
- 비디오 크기 최대 1GB 제한
- 클라우드 서비스 활용하면 좋음
  <br>일 때, 다음 기능 중심으로 설계를 진행한다.
    - 빠른 비디오 업로드
    - 원활한 비디오 재생
    - 재생 품질 선택
    - 낮은 인프라 비용
    - 가용성, 규모 확장성, 안정성
    - 모바일 앱, 웹, 스마트 TV
      <br>

### 개략적 규모 추정
- DAU 500만
- 평균 사용자 당 5개 비디오 시청
- 10% 사용자는 비디오 1개 업로드
- 비디오 평균 크기 300MB
- 매일 저장 요구 용량: 5백만×10%×300MB = 150TB
- CDN 비용:
- - 클라우드 CDN 의 경우, 데이터 양에 따라 과금 (아마존은 1GB 당 $0.02)
- - 5백만×5비디오×0.3GB×$0.02 = $150,000
    <br>

## 개략적 설계안 제시 및 동의 구하기
CDN 과 BLOB 스토리지 (기존 클라우드) 활용
- 시스템 디자인 면접은 모든 것을 처음 부터 할 필요는 없음
  <br>

이 시스템은 사용자 단말, CDN, API 서버 세 개의 컴포넌트로 구성된다.
- 단말(client): 컴퓨터, 포느 스마트 TV
- CDN: 비디오는 CDN 에 저장, 재생 시 CDN 으로 스트리밍
- API 서버: 스트리밍을 제외한 모든 요청은 API 서버가 처리한다. 피드 추천, 비디오 업로드 URL 생성, 메타데이터 데이터베이스, 캐시 갱신 등
  <br><br>

### 비디오 업로드 절차
![img](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FlAtxI%2FbtsIHd3h42m%2FRypyzMK8YTKIFUkgMDTls0%2Fimg.png)
- 사용자: 단말을 통해 유튜브 시청
- 로드 밸런서: API 서버 각각 고르게 분산
- API 서버: 비디오 스트리밍 외 나머지 요청 처리
- 메타데이터 데이터베이스: 비디오의 메타데이터 보관
  <br>샤딩, 다중화를 적용하여 성능, 가용성 요구사항을 충족
- 메타데이터 캐시: 비디오 메타데이터, 사용자 객체를 캐시하여 성능 향상
- 원본 저장소: 원본 비디오 저장하는 이진 파일 저장소(BLOB) 시스템 (BLOB: 이진 데이터를 개체로 보관하는 DBMS)
- 트랜스코딩 서버: 비디오 인코딩이라고도 부른다.  비디오 포맷(MPEG, HLS 등) 변환하는 절차.
  <br>대역폭, 단말 요구사항에 맞는 최적 비디오 스트림 제공하기 위해 필요
- 트랜스코딩 비디오 저장소: 트랜스코딩 완료된 비디오 저장하는 BLOB 저장소
- CDN: 비디오 캐시하는 역할, 스트리밍도 이곳에서 이루어짐
- 트랜스코딩 완료 큐: 비디오 트랜스코딩 완료 이벤트 보관하는 메시지 큐
- 트랜스코딩 완료 핸들러: 트랜스코딩 완료 큐에서 이벤트 데이터를 꺼내 메타데이터 캐시와 데이터베이스 갱신 작업 서버
  <br><br>

프로세스 a. 비디오 업로드
1. 원본 저장소에 비디오 업로드
2. 트랜스 서버: 원본 저장소에서 비디오 가져와  트랜스코딩 시작
3. 트랜스코딩 완료 시 병렬 수행
    - 3a.1. 트랜스코딩 끝난 비디오 CDN 업로드
    - 3b.1. 완료 핸들러가 이벤트 데이터에서 큐 꺼냄
    - 3b.1.a, 3b.1.b. 완료 핸들러가 메타데이터 데이터베이스, 메타데이터 캐시 갱신
4. API 서버가 단말기에 스트리밍 준비 완료를 알림
   <br><br>

프로세스 b. 메타데이터 갱신
원본 저장소에 업로드 되는 동안 단말은 병렬적으로 비디오 메타데이터 갱신 요청을 API 서버에 보냄<br>
API 서버는 이 정보로 메타데이터 캐시, 데이터베이스 업데이트
<br><br>

### 비디오 스트리밍 절차
스트리밍 프로토콜은 데이터를 전송할 때 쓰이는 표준화된 통신방법으로 다음과 같은 종류가 있다.
- MPEG_DASH, (Moving Picture Experts Group) + (Dynamic Adaptive Streaming over HTTP)
- APPLE HLS, (HTTP Live Streaming
- Microsoft Smotth Streaming
- Adobe HTTP Dynamic Streaming, HDS)
  <br>
  비디오 스트리밍 서비스 설계시 서비스 용례에 맞는 프로토콜을 선택해야 한다.
  <br>
  비디오는 CDN에서 스트리밍 된다. 사용자 단말에 가까운 CDN 에지 서버가 비디오 전송을 담당할 것이며, 전송 지연을 낮춘다.

## 상세 설계
전체 시스템을 비디오 업로드와 비디오 스트리밍으로 나눴고 최적화 방안과 오류 처리 매커니즘을 살펴본다.

### 비디오 트랜스코딩
비디오를 녹화할 때, 단말은 특정 포맷으로 저장하게 된다. 여러 단말에 호환이 되려면 비트레이트와 포맷으로 저장되어야 한다.
<br>비트레이트는 비디오 비트의 처리 속도 단위이다. 비트레이트가 높은 비디오는 고화질이고, 이를 정상 재생하려면 높은 성능의
컴퓨팅 파워, 인터넷 회선 속도가 빨라야 한다.
<br>
비디오 트랜스코딩은 다음 이유로 중요하다.
- raw video 는 저장 공간이 많이 차지한다.
- 많은 단말과 브라우저는 특정 비디오 포맷만 지원한다. 따라서 여러 포맷으로 인코딩 해두어야 한다.
- 끊김 없는 비디오 공급하기 위해서는 네트워크 대역폭에 따라 저화질~고화질 비디오로 공급해주는 것이 맞다.
- 모바일 단말은 네트워크 상황이 수시로 달라진다. 비디오가 끊김 없이 재생되려면 화질을 자동 변경하거나 수동 변경을 할 수 있어야 한다.
  <br><br>

인코딩 포맷은 대부분 두 부분으로 구성되어 있다.
- 컨테이너: 비디오 파일, 오디오, 메타데이터를 담는 바구니이다. 컨테이너 포맷은 .avi, .mov, .mp4 확장자가 있다.
- 코덱: 비디오 화질을 보존하며 파일 크기를 줄일 목적으로 만들어진 압축·압축 해제 알고리즘. H.264, VP9, HEVC등이 있다.
  <br>

### 유향 비순환 그래프(DAG) 모델
각 유형의 비디오 프로세싱 파이프라인을 지원하고, 처리과정의 병렬성을 높여야 한다. 추상화를 도입하여 클라이언트 프로그래머가
실행할 작업을 손수 정의할 수 있어야 한다. 예를 들어, 페이스북 스트리밍 비디오 엔진은 유향 비순환 그래프 (DAG)을 도입해
작업을 단계별로 배열한다. 작업들이 순차적 혹은 병렬적으로 실행할 수 있도록 한다.
<br>
![img](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbQiUhI%2FbtsIHda9nVm%2FYQOP2dv0wjaIJdKEwnwjuK%2Fimg.png)
<br>raw video 는 비디오, 오디오, 메타데이터 세 부분으로 나뉘어 처리된다. 비디오 부분의 작업처리는 다음과 같다.
- 검사: 좋은 품질인지, 손상은 없는지 확인
- 비디오 인코딩: 해상도, 코덱, 비트레이트 조합으로 인코딩
- 섬네일: 사용자가 업로드한 이미지, 비디오에서 자동 추출된 이미지로 섬네일을 만드는 작업
- 워터마크: 식별정보를 이미지 위에 오버레이 형태로 띄워 표시하는 작업
  <br><br>

### 비디오 트랜스코딩 아키텍처
트랜스 코딩 아키텍처는 다음과 같다. 다섯 개의 주요 컴포넌트로 구성되며, 아키텍처가 동작한 결과로 인코딩된 비디오가 생성된다.
<br>
![img](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FvQPse%2FbtsIIxT1JR0%2FgkIu9kEHMrH2XF5kQNkum1%2Fimg.png)
<br>

##### 전처리기
1. 비디오 분할(video spliting): 비디오 스트림을 GOP(Group of Pictures)단위로 쪼갠다. GOP는 특정 순서로 배열된 프레임 그룹이다.
   하나의 GOP는 독립 재생이 가능하고 길이는 몇 초 이다. 어떤 단말은 GOP 를 지원하지 않기 때문에 전처리기가 비디오 분할을 대신한다.
2. DAG 생성: 클라이언트 프로그래머가 장성한 설정 파일에 DAG 를 만든다. 두 개의 노드와 한 개의 연결선으로 구성된 DAG는 아래 두 파일로 생성됐다.
   <br>![img](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FuYyjR%2FbtsIzTklgMI%2FRrhsDJzwhWEVkl8DhMCFjK%2Fimg.png)
![img](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcZmNFo%2FbtsIATRi6cC%2FCXj6VOTjhkwvHUB4mviNk1%2Fimg.png)
3. 데이터 캐시: 전처리기는 분할된 비디오의 캐시다. 안정성을 높이기 위해 GOP와 메타데이터를 임시 저장소에 보관한다.
   <br>

##### DAG 스케줄러
DAG 그래프를 몇 단계로 분할한 후 자원 관리자의 작업 큐에 집어 넣는다.
<br>![img](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbxLFDM%2FbtsIHB3Ux2u%2F2EhDgyxLna1AKsZvjcshs1%2Fimg.png)<br>
DAG 그래프를 2 단계로 쪼갠 사례다. 첫 단계에서는 비디오, 오디오, 메타데이터로 분리한다. 두 번째 단계는 해당 비디오 파일을 인코딩, 섬네일 추출,
오디오 파일 인코딩한다.
<br>

##### 자원 관리자
자원 관리자는 자원 배분을 효과적으로 수행한다. 세 개의 큐와 작업 스케줄러로 구성한다.
<br>![img](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FciLNXo%2FbtsIIkm5jhk%2Faway20FNqc84i3hq1Xi6t1%2Fimg.png)<br>
- 작업 큐: 실행 작업이 보관된 우선순위 큐
- 작업 서버 큐: 작업 서버의 가용 상태가 저장된 우선순위 큐
- 실행 큐: 실행 중인 작업과 작업 서버가 저장된 큐
- 작업 스케줄러: 최적의 작업/서버를 골라 해당 작업 서버가 작업할 수 있도록 지시
  <br>
  작업 관리자의 동작은 다음과 같다.
- 작업 관리자는 작업 큐에서 높은 우선순위 작업을 꺼냄
- 작업 관리자는 작업을 실행할 적절 서버를 고름
- 작업 스케줄러는 작업 서버에 작업 실행을 지시
- 작업 스케줄러는 어떤 서버에 할당되었는지 정보를 실행 큐에 넣음
- 작업 스케줄러는 작업 완료시 실행 큐에서 제거
  <br>

##### 작업 서버
작업 서버는 DAG 에 정의된 작업을 수행한다. 워터마크, 인코딩, 섬네일, 병합 등의 작업 종류에 따라 작업 서버도 구분하여 관리한다.
<br>

##### 임시 저장소
임시 저장소 구현은 여러 시스템을 활용할 수 있다. 저장 데이터는 메모리에 캐시해 두면 좋다. 그러나, 비디오/오디오 데이터의 경우, BLOB 저장소에 둬야 한다.
비디오 프로세싱 완료시 임시 저장소에 저장된 데이터는 삭제한다.
<br>

##### 인코딩된 비디오
인코딩 파이프라인의 최종 결과물이다.
<br>


### 시스템 최적화
속도, 안전성, 비용 측면에서의 시스템 최적화를 다룬다.
<br>

##### 속도 최적화 1: 비디오 병렬 업로드
비디오를 한번에 업로드 하는 것 보다 *GOP로 분할*하여 *병렬적*으로 업로드 한다. 일부 실패해도 업로드 재개하기 용이하여 업로드 속도를 높일 수 있다.
<br>

##### 속도 최적화 2: 업로드 센터를 사용자 근거리에 지정
업로드 센터를 여러 곳에 두는 방법이다.
<br>

##### 속도 최적화 3: 모든 절차를 병렬화
느슨한 결합 시스템을 만들어 병렬성을 높인다.
기존 설계안으로는 전 단계의 의존도가 높기 때문에 병렬성을 높이기 어렵다.
<br>![img](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbbNzvT%2FbtsIHKsXv2z%2F7i29RSWs7YTEJOt8JIjEWk%2Fimg.png) <br>
메시지 큐를 이용하면 결합도를 낮출 수 있다.
- 도입 전: 인코딩 모듈은 다운로드 모듈 작업을 기다렸다.
- 도입 후: 인코딩 모듈은 다운로드 모듈을 기다리지 않는다. 메시지 큐에보관된 이벤트를 병렬적으로 처리할 수 있다.
  <br>

##### 안전성 최적화 1: 미리 사인된 업로드 URL
authorized 사용자만 비디오 업로드를 할 수 있게 pre-signed 업로드 URL을 이용한다.
<br> ![img](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbEIVJi%2FbtsIIzK4LRs%2F8qErAORgmG9l3klhpCldK0%2Fimg.png) <br>
1. 클라이언트는 HTTP 서버에 POST 요청으로 pre-signed URL 받는다.
2. API 서버는 pre-signed URL 을 반환한다.
3. 클라이언트는 URL 이 가리키는 위치에 비디오를 업로드한다.
   <br>

##### 안전성 최적화 2: 비디오 보호
비디오 저작권 보호를 위한 세 가지 방안이 있다.
- 디지털 저작권 관리(DRM) 도입: 애플의 페어플레이, 구글의 와이드 바인, 마이크로소프트의 플레이레디
- AES 암호화: 비디오 암호화 후 접근하는 방식. 재생 시에 복호화 되며 허락한 사용자만 시청 가능함
- 워터마크
  <br>

##### 비용 최적화
CDN 은 시스템의 핵심 부분이다. 유튜브의 비디오 스트리밍은 롱 테일 분포를 따른다. 이에 착안하여 설계한다.
<br>![img](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbKNbhJ%2FbtsIG9GJNmL%2Fte2qKh4L9cPHGrWkAGVPjK%2Fimg.png) <br>
1. 인기 비디오는 CDN 통해 재생, 다른 비디오는 비디오 서버 통해 재생
2. 인기 없는 비디오는 인코딩 필요 없을 수 있다. 짧은 비디오도.
3. 특정 지역에서만 인기 많은 비디오는 다른 지역에 옮길 필요 없다.
4. CDN 직접 구축, ISP 제휴한다. 이는 초대형 프로젝트가 될 것이다.
   <br>

##### 오류 처리
-회복 가능 오류(recoverable error): 비디오 세그먼트를 트랜스코딩하다 실패한 것 같은 오류는 회복 가능하다. 재시도로 해결 가능하다.
계속된 실패시, 복구 어렵다 판단되면 클라이언트에게 오류 코드를 반환한다.
- 회복 불가능 오류 (non-recoverable error): 비디오 포맷의 문제 같은 오류는 해당 비디오 작업을 중단하고 클라이언트에게 오류 코드를 반환한다.
  <br>
  다음 전형적 오류의 해결방안이다.
- 업로드 오류: 몇 회 재시도
- 비디오 분할 오류: 낡은 버전의 클라이언트가 GOP 경계에 비디오 분할 못하는 경우는 전체 비디오를 서버에 전송한다. 서버가 비디오 분할 처리
- 트랜스코딩 오류: 재시도
- 전처리 오류: DAG 그래프 재생성
- DAG 스케줄러 오류: 작업 다시 스케줄링
- 자원 관리자 큐 장애 발생: replica 이용
- 작업 서버 장애: 다른 서버에서 재시도
- API 서버 장애: 무상태 서버라 신규 요청은 다른 API 서버로 우회
- 메타데이터 캐시 서버 장얘: 데이터는 다중화되므로 다른 노드에서 데이터 가져올 수 있다. 장애난 캐시서버는 교체
- 메타데이터 데이터베이스 서버 장애:
- - 주 서버가 죽었으면 부 서버 가운데 하나를 주 서버로 교체
- - 부 서버가 죽었으면 다른 부 서버를 읽기 연산 처리, 죽은 부 서버는 새 것으로 교체
    <br><br>

## 마무리
다음 논의해 볼 것
- API 계층의 규모 확장성 확보 방안: API 서버는 무상태 서버로 수평적 규모 확장이 가능하다는 것을 언급
- 데이터베이스 계층 규모 확장성 확보 방안: 데이터베이스 다중화와 샤딩
- 라이브 스트리밍: 라이브와 비라이브 간에는 비디오 업로드, 인코딩, 스트리밍이 필요하다. 그러나 다른점은 다음과 같다.
- - 라이브 스트리밍은 응답 지연이 더 낮아야 한다. 스트리밍 프로토콜 선정에 유의!
- - 라이브 스트리밍은 병렬화 필요성이 낮다. 작은 단위 데이터를 실시간으로 빨리 처리하기 때문이다.
- - 라이브 스트리밍은 오류 처리시 오랜 시간이 걸리면 안 된다.
- 비디오 삭제(takedown): 저작권 위반 비디오 등은 내려야 한다.

***

# 15장 구글 드라이브 설계
## 문제 이해 및 설계 범위 확정
파일 업로드/다운로드, 동기화, 알림, 웹과 앱 지원, 파일 암호화, 10GB 제한, DAU 10M(천만)
- 파일 추가 (drag-and-drop)
- 파일 다운로드
- 파일 동기화 (다른 단말에서 자동 동기화)
- 파일 갱신 이력 조회(revision history)
- 파일 공유
- 파일 편집, 삭제 등 알림표시

<br>구글 문서 편집, 협업 기능은 제외한다.
<br>기능적 외의 비기능적 요구사항은 다음과 같다.
- 안정성: 데이터 손실이 일어나면 안됨
- 빠른 동기화 속도
- 네트워크 대역폭
- 규모 확장성: 방대한 트래픽도 처리 가능해야 한다.
- 높은 가용성: 장애 발생하여도 사용 가능해야 한다.

<br>

### 개략적 추정치
- 가입은 50M, 사용자는 10M 가정
- 사용자 당 10GB 무료 저장공간 할당
- 매일 사용자는 2개 파일 업로드 가정. 평균 크기 500KB
- 읽기:쓰기 = 1:1
- 필요 저장공간 = 50M × 10GB=500PB
- 업로드 API QPS = 10M × 2회 업로드 / 24h / 3600s ≒ 240
- 최대 QPS = QPS × 2 = 480
<br>

## 개략적 설계안 제시 및 동의 구하기
한 대의 서버에서 점차 수정해 나가는 방식으로 톺아볼 것이다.
- 파일 업로드, 다운로드 처리 웹 서버
- 메타데이터 보관할 DB
- 파일 저장소 시스템 (1TB)

<br>

### API
파일 업로드, 다운로드, 파일 갱신 히스토리 제공 세 가지 API 가 필요하다.
1. 파일 업로드 API: 두 종류의 업로드 지원한다.
    - 단순 업로드: 파일 크기가 작을 떄 사용
    - 이어 올리기(resumable upload): 파일 사이즈가 크고, 네트워크로 업로드 중단 대비할 떄 사용
        > 예시 https://api.example.com/files/upload?uploadType=resumable
        <br>인자<br>
        - uploadType=resumable
        - data: 업로드 할 로컬 파일
      <br>이어 올리기의 절차
        1. 이어 올리기 URL 을 받기 위해 최초 요청 전송을 한다.
        2. 데이터 업로드, 상태 모니터링
        3. 업로드 장애 발생시 발생 시점부터 재시작
2. 파일 다운로드 API:     
 >예시
> https://api.example.com/files/download
 > <br>인자<br>
 > - path: 다운로드 할 파일 경로
 > - - {"path": "/recipes/soup/best_soup.txt"}

3. 파일 갱신 히스토리 API
>예시
> https://api.example.com/files/list_revisions
> <br>인자<br>
> - path: 갱신 히스토리를 가져올 파일 경로
> - limit: 히스토리 길이 최대치
> - - {"path": "/recipes/soup/best_soup.txt", <br>"limit": 20}

<br>
지금의 API는 사용자 인증을 필요로 하고 HTTPS 프로토콜을 사용한다. SSL 지원하는 프로토콜 사용 이유는
클라이언트와 서버 간의 주고받는 데이터 보호하기 위함이다.
<br><br>

### 한 대 서버 제약 극복
업로드가 많아지면 파일 시스템이 가득 찰 것이다. 먼저 샤딩하여 여러 서버에 나누어 저장하는 방법이 있다.
AWS S3을 사용하여 다중화를 하게 된다면 데이터 손실을 막고 가용성을 최대로 보장할 수 있다. S3 버킷은 파일 시스템의 폴더랑 같다.
- 로드밸런서: 네트워크 트래픽 분산으로 사용한다. 특정 웹 서버에 장애 발생 시 자동으로 서버 우회도 할 수 있다.
- 웹 서버: 로드밸런서 추가 후 웹 서버 손쉽게 추가 가능하며 트래픽 폭증시 대응도 가능하다.
- 메타데이터 DB: DB를 파일 저장 서버에서 분리하여 SPOF 방지한다. 다중화 및 샤딩 정책으로 가용성과 규모 확장성 대응한다.
- 파일 저장소: S3 파일 저장소로 사용하고 다중화 하여 데이터 무손실을 보장하고 가용성을 보장한다.

<br>

### 동기화 충돌
두 명 이상이 동시 업데이트 시 동기화가 충돌될 수 있다.
먼저 처리되는 것은 변경 성공, 나중 처리되는 것은 충돌 발생으로 표시한다.
<br>오류 발생 시점에 파일의 원본과 사본 파일이 존재하게 되고 합치거나 대체하거나 식으로 변경하게 된다.
<br><br>

### 개략적 설계안
- 사용자 단말
- 블록 저장소 서버(block server): 파일 블록을 클라우드 저장소에 업로드하는 서버. 블록 수준 저장소(block-level storage) 라고도 한다.
파일을 여러개의 블록으로 나누어 저장하고 고유 해시값을 할당한다. 해시 값은 메타데이터 DB에 저장하며, 각 블록이 독립된 객체가 돼 S3에 보관된다.
만일 재구성 할 시 블록을 원래 순서로 합쳐야 한다. (해당 설게안은 드롭박스 사례로 4MB로 정한다.)
- 클라우드 저장소: 블록 단위 파일이 이곳에 저장된다.
- 아카이빙 저장소(cold storage): 비활성 데이터 저장한다.
- 로드밸런서
- API 서버: 파일 업로드 외의 대부분을 담당하는 서버
- 메타데이터 DB: 메타데이터 정보 관리.
- 메타데이터 캐시: 자주 쓰이는 메타데이터 캐시
- 알림 서비스: 이벤트 발생시 클라이언트에게 알림가는 발생구독 프로토콜 기반 시스템(파일 갱신시 알림)
- 오프라인 사용자 백업 큐(offline backup queue): 클라이언트 오프라인 시 해당 큐에 넣고 온라인 될 때 동기화 될 수 있게 한다.

<br>

## 상세 설계
### 블록 저장소 서버
한 파일을 한번에 올리면 네트워크 대역 폭이 많이 사용되기 때문에 최적화를 해야하고 두 방법을 고안할 수 있다.
- 델타 동기화(delta sync): 파일 수정시 수정 블록만 동기화
- 압축: 블록 단위로 압축하기
보통의 블록 저장소 서버는 파일 업로드 시 고충을 해결하는 컴포넌트다.<br><br>

- 파일을 작은 블록으로 분할
- 블록 압축
- 암호화
- 클라우드 저장소로 전송

<br>

### 높은 일관성 요구사항
강한 일관성 모델을 기본 지원하기에 같은 파일이 단말 혹은 사용자한테 다르게 보여서는 안 된다.
메모리 캐시는 결과적 일관성(eventual consistency)모델을 지원한다.
강한 일관성 모델을 지원하기 위해서는 두 가지를 보장해야 한다.
- 캐시 사본과 DB 원본(master)이 일치할 것
- DB 원본을 변경 시, 캐시 사본을 무효호한다.

<br>RDBMS 는 ACID 를 보장해서 일관성을 보장할 수 있다. 그러나 NoSQL DBMS 는 동기화 로직 안에 해당 기능을 넣어야 한다.
본 설계안은 RDBMS 를 사용한다고 가정한다.
<br>

### 메타데이터 데이터베이스
- user: user 정보
- device: 단말 정보
- namespace: 사용자 루트 디렉터리 정보
- file: 파일 최신 정보
- file_version: 파일 갱신 이력 보관 테이블
- block: 파일 블록 정보

<br>

### 업로드 절차
**파일 메타데이터 추가**
1. 클라이언트 1이 새 파일 메타데이터 추가 요청
2. 새 파일의 메타데이터를 DB에 저장 후 업로드 상태 pending 변경
3. 새 파일 추가를 알림 서비스에 통지
4. 알림 서비스는 관련 클라이언트 2에게 알림

<br>

**파일 클라우드 저장소에 업로드**
1. 클라이언트 1이 파일을 블록 저장소 서버에 업로드
2. 블록 저장소 서버는 파일을 블록으로 쪼개고 압축, 암호화 한 후 클라우드 저장소 전송
3. 업로드 끝나면 클라우드 저장소는 완료 콜백 호출 (API 서버 전송)
4. 메타데이터 DB 에 기록된 파일 상태를 완료(uploaded) 변경
5. 알림 서비스에 통지
6. 알림 서비스는 클라이언트 2에게 업로드 알림

수정도 비슷한 프로세스로 흘러간다.
<br>

**다운로드 절차**
<br>파일 새로 추가되거나 편집되면 자동 시작한다.
파일의 변화를 감지하는 방법은 두 가지가 있다.

- 클라 1이 접속중이고 클라 2가 파일 변경시 알림 서비스가 클라 1에게 알림
- 클라 1이 오프라인일 경우 데이터는 캐시에 보관된다.

<br>
파일 변경을 알게 된 클라이언트는 API 서버로 메타데이터를 가져간다. 다음으로 블록을 다운 받고 파일 재구성한다.

1. 알림 서비스가 클라 2에게 파일 변경 알림
2. 알림 확인 클라2는 새 메타데이터 요청
3. API 서버는 메타데이터 DB 에 새 메타데이터 요청
4. API 서버에 새 메타데이터 반환
5. 클라 2에게 반환
6. 클라 2는 반환 즉시 블록 다운로드 요청 전송
7. 블록 저장소 서버는 클라우드 저장소에서 블록 다운로드
8. 클라우드 저장소는 블록 서버로 부터 요청 블록 반환
9. 블록 저장소 서버는 클라이언트 요청 블록 반환, 클라2는 전송 블록으로 파일 재구성

<br>

**알림 서비스**
<br>
파일 수정 감지 순간 알림을 통해 충돌 방지를 한다.

- 롱 폴링: 드롭 박스가 채택하는 방식
- 웹 소켓: 클라와 서버 사이의 지속적 통신 채널 제공하기에 양방향 통신 가능

<br>
두 방안 중 *롱 폴링* 방식을 차용한다.

- 본 시스템은 양방향 통신이 필요하지 않기 떄문 (양방향은 채팅 서비스에 적합)

롱 폴링 차용시 각 클라는 알림 서버와 연결 유지하다 특정 파일이 변경 감지시에 해당 연결을 끊는다.
클라는 반드시 메타데이터 서버와 연결을 통해 최신 파일 내역을 다운로드한다.
다운로드 끝났거나 연결 타임아웃 시 새 요청을 보내 롱 폴링 연결 복원, 유지한다.
<br><br>

**저장소 공간 절약**
<br>파일 갱신 이력 보관과 동시에 안정성을 보장하기 위해서는 여러 버전의 파일을 데이터센터에 보관하는 것이 좋다.
저장 용량을 효율적으로 쓰기 위해 세 방안이 있다.
1. 중복 제거(de-dupe): 중복 파일 블록을 제거한다. (해시 값 비교)
2. 백업 전략 도입:
    - 한도 설정: 파일 버전 개수에 제한
    - 중요 버전만 보관
3. 자주 안쓰이는 데이터는 아카이빙 저장소(cold storage)로 옮긴다.

<br>

**장애 처리**
- 로드밸런서 장애: 부 로드밸런서가 활성화 후 트래픽을 이어 받는다. 박동 신호를 보내서 상태 체크를 한다.
- 블록 저장소 서버 장애: 다른 서버가 이어받는다.
- 클라우드 저장소 장애: S3 버킷은 여러 지역에 다중화 할 수 있어서 다른 지역에서 파일 가져온다.
- API 서버 장애: API 는 무상태 서버라서 로드 밸런서가 해당 서버로 보내지 않을 것이다.
- 메타데이터 캐시 장애: 메타데이터 캐시 서버도 다중화 하여 다른 노드에서 가져온다.
- 메타데이터 DB 장애:
  - 주 데이터베이스 서버 장애: 부 DB 중 하나를 주 DB 로 변경하고 부 DB 서버를 추가한다.
  - 부 데이터베이스 서버 장애: 다른 부 DB 서버가 읽기 연산 처리하고 그동안 장애 서버는 새로 교체한다.
- 알림 서비스 장애: 온라인 사용자에게 롱 폴링 연결을 한다. 한 대 서버 장애 발생시 백만 명의 이상의 사용자의 
롱 폴링을 다시 만들어야 한다. 따라서 느릴 수 있다.
- 오프라인 사용자 백업 큐 장애: 다중화 해 둔다. 백업 큐로 구독 관계 재설정 한다.

<br>

## 마무리
설계안은 파일의 메타데이터 관리 부분과 파일 동기화 처리하는 부분으로 나눌 수 있다.
알림 서비스는 함께 존재하며 롱 폴링으로 파일 상태 최신으로 유지한다.
따로 고려해볼 사항이라면, 블록 저장소 서버 말고 바로 클라우드 저장소에 파일을 업로드 할 경우를 생각해 본다.
이 경우, 업로드 시간이 빨라진다는 장점이 생길 것 이다. 그러나 단점이 생긴다.
- 분할, 압축, 암호화 로직을 클라이언트에 둬야 해서 플랫폼 별로 구현해야 한다.
- 해킹당할 가능성을 염두해야 한다.

<br>
또 하나 고려할 점은 온/오프라인 관리 로직은 별도 서비스로 옮기는 것이다.

<br><br>
## 자료, 참조
- Alex Xu, (2021). 가상 면접 사례로 배우는 대규모 시스템 설계 기초, 인사이트




